# Fast Food Classification V2
# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DkHXpw8Uib5CTvIoddMtIkCkLRwVAqgl
"""

! pip install -q kaggle

from google.colab import files

files.upload()

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/
! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d utkarshsaxenadn/fast-food-classification-dataset

! unzip "utkarshsaxenadn/fast-food-classification-dataset"



! unzip /content/fast-food-classification-dataset.zip



import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import classification_report, accuracy_score, f1_score
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50V2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

# Paths
data_dir = "utkarshsaxenadn/fast-food-classification-dataset"
train_dir = os.path.join(data_dir, "/content/Fast Food Classification V2/Train")
test_dir = os.path.join(data_dir, "/content/Fast Food Classification V2/Test")

# Params
image_size = (224, 224)
batch_size = 32
num_classes = 10  # Adjust if your dataset has a different number

# Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.2,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True
)

test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False
)

# Load Pre-trained Model
base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze base initially

# Add custom classification head
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
predictions = Dense(num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# Compile
model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Callbacks
checkpoint = ModelCheckpoint('best_resnet50v2.h5', save_best_only=True, monitor='val_accuracy', mode='max')
early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)

# Train
history = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=5,
    callbacks=[checkpoint, early_stop, reduce_lr]
)

# Fine-tune: unfreeze top layers
base_model.trainable = True
for layer in base_model.layers[:-50]:  # Fine-tune top 50 layers
    layer.trainable = False

# Recompile with lower learning rate
model.compile(optimizer=Adam(learning_rate=1e-5),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Continue training
fine_tune_history = model.fit(
    train_generator,
    validation_data=test_generator,
    epochs=5,
    callbacks=[checkpoint, early_stop, reduce_lr]
)

# Evaluate
y_true = test_generator.classes
y_pred_probs = model.predict(test_generator)
y_pred = np.argmax(y_pred_probs, axis=1)

# Metrics
acc = accuracy_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred, average='weighted')

print(f"\n‚úÖ Accuracy: {acc:.4f}")
print(f"‚úÖ F1 Score: {f1:.4f}")

# Classification Report
class_labels = list(test_generator.class_indices.keys())
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_labels))

def plot_training_history(history, fine_tune_history=None):
    def combine_histories(h1, h2):
        combined = {}
        for key in h1.history:
            combined[key] = h1.history[key] + (h2.history[key] if h2 else [])
        return combined

    combined_history = combine_histories(history, fine_tune_history)

    epochs = range(1, len(combined_history['accuracy']) + 1)

    plt.figure(figsize=(16, 5))

    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(epochs, combined_history['accuracy'], label='Training Accuracy')
    plt.plot(epochs, combined_history['val_accuracy'], label='Validation Accuracy')
    plt.title('Model Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(epochs, combined_history['loss'], label='Training Loss')
    plt.plot(epochs, combined_history['val_loss'], label='Validation Loss')
    plt.title('Model Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    plt.tight_layout()
    plt.show()

from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import os

# Load model using full path if not in current working directory
# Changed the filepath to the saved model file
model = load_model("best_resnet50v2.h5")

# Load a real image (not a .tfrecord)
# Note: This path might need to be adjusted if running on Colab and the image is not accessible
# The example path "C:/Users/asus/Documents/Fast Food Classification V2/Baked Potato_1.jpg" is a Windows path
# and will not work directly in a Linux environment like Colab.
# You would need to upload an image to the Colab environment and use its path.
# For demonstration, we'll use a placeholder or assume an image is uploaded.
# For example, if you upload an image named 'test_image.jpg' directly to Colab:
img_path = "C:\\Users\\asus\\Documents\\Fast Food Classification V2" # Placeholder - Replace with actual image path
if not os.path.exists(img_path):
    print(f"Warning: Image file not found at {img_path}. Skipping prediction.")
    # You might want to add code here to upload or locate an image if needed.
else:
    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    # Make prediction
    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions)
    print(f"Predicted class index: {predicted_class}")

    # Optional: Print class name if available
    # You would need the class_names list from your training setup
    # e.g., class_names = list(test_generator.class_indices.keys())
    # if 'class_names' is defined:
    #     print(f"Predicted class name: {class_names[predicted_class]}")

!pip install streamlit

"""# New Section"""

# app.py
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from PIL import Image, ImageOps
import numpy as np
import os

# --- Page Configuration (MUST BE THE FIRST STREAMLIT COMMAND) ---
st.set_page_config(page_title="Fast Food Classifier", layout="centered")

# --- Other Configuration ---
# Suppress TensorFlow INFO and WARNING messages
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
tf.get_logger().setLevel('ERROR')

MODEL_PATH = 'best_resnet50v2.h5'
IMAGE_WIDTH = 224
IMAGE_HEIGHT = 224
CLASS_LABELS = ['burger', 'cake', 'chicken', 'donuts', 'fries', 'hot_dog', 'ice_cream', 'pizza', 'sandwich', 'waffles']  # Update to match your dataset

# --- Model Loading ---
@st.cache_resource
def load_my_model():
    """Loads the pre-trained Keras model."""
    try:
        model = load_model(MODEL_PATH)
        return model
    except Exception as e:
        st.error(f"Error loading model: {e}")
        st.error(f"Ensure '{MODEL_PATH}' is in the correct location and is a valid Keras model file.")
        return None

model = load_my_model()

# --- Image Preprocessing ---
def preprocess_image(image_pil):
    """Preprocesses the uploaded image to fit model input requirements."""
    image_resized = image_pil.resize((IMAGE_WIDTH, IMAGE_HEIGHT))
    if image_resized.mode != 'RGB':
        image_resized = image_resized.convert('RGB')
    image_array = np.array(image_resized)
    image_array = image_array / 255.0
    image_batch = np.expand_dims(image_array, axis=0)
    return image_batch

# --- Streamlit App UI ---
st.title("üçî Fast Food Image Classifier")
st.markdown("""
Upload an image of a fast food item. This app uses a ResNet50V2 model to predict the type of food.
""")

uploaded_file = st.file_uploader("Choose a fast food image...", type=["jpg", "jpeg", "png"])

if model is None:
    st.warning("Model could not be loaded. Please check the console or logs.")
else:
    if uploaded_file is not None:
        try:
            image = Image.open(uploaded_file)
            st.image(image, caption='Uploaded Image.', use_column_width=True)
            st.write("")

            with st.spinner('Analyzing the image...'):
                processed_image = preprocess_image(image)
                prediction = model.predict(processed_image)
                predicted_class_index = np.argmax(prediction[0])

                if predicted_class_index < len(CLASS_LABELS):
                    predicted_class_label = CLASS_LABELS[predicted_class_index]
                    confidence = np.max(prediction[0]) * 100

                    st.subheader("üîç Prediction:")
                    st.success(f"**{predicted_class_label.replace('_', ' ').title()}**")
                    st.write(f"Confidence: **{confidence:.2f}%**")

                    st.write("---")
                    st.write("Confidence Scores for all classes:")
                    for i, label in enumerate(CLASS_LABELS):
                        st.write(f"- {label.replace('_', ' ').title()}: {prediction[0][i]*100:.2f}%")
                else:
                    st.error(f"Prediction index {predicted_class_index} is out of bounds for CLASS_LABELS.")
                    st.error("Please ensure CLASS_LABELS in app.py matches the training classes and their order.")
        except Exception as e:
            st.error(f"An error occurred processing the image: {e}")
            st.error("Please ensure you uploaded a valid image file.")
    else:
        st.info("Awaiting an image upload to start analysis.")

st.markdown("---")
st.markdown("Developed for fast food classification using ResNet50V2 and TensorFlow/Keras.")

